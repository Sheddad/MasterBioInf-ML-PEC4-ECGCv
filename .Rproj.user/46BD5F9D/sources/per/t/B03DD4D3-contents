---
title: "PEC 4 Machine Learning"
author: "Sheddad Kaid-Salah Ferrón"
date: "`r format(Sys.Date())`"
output:
  html_document:
    code_folding: hide
    toc: true
    toc_float: no
    toc_depth: 3
    theme: flatly
    number_sections: false
    csl: vancouver.csl
  pdf_document:
    toc: yes
params:
  date: !r Sys.Date()
  printcode:
    label: "Display Code:"
    value: TRUE # or set it to FALSE
  data:
    label: "Input dataset:"
    value: ECGCvdata.csv
    input: file
  folder.data: ""
  p.train: !r 2/3
  subtitulo: Predicción de dolencias cardiacas a partir de electrocardiograma
  seed: 12345
nocite: |
  @lantz2015machine
  @pec_ml_4
bibliography: PEC_4_ML.bib
geometry: margin=2cm
---

```{r class.source = 'fold-hide', setup, include=FALSE}
# Parametrizamos
require(knitr)
require(rmdformats)

## Global options
options(max.print="75")
opts_chunk$set(echo=params$printcode,
	             cache=TRUE, # para no reproducir cuando no hay cambios 
               prompt=FALSE,
               tidy=TRUE,
               comment=NA,
               message=FALSE,
               warning=FALSE)
opts_knit$set(width=75)
Sys.setlocale("LC_TIME", "C")
```

``` {r paquetes, include=FALSE}
# Instalamos paquetes, si no lo están, en caso de ser requeridos
if(!(require(knitr))) install.packages("knitr")
if(!(require(rmdformats))) install.packages("rmdformats")
if(!(require(reticulate))) install.packages("reticulate")
if(!(require(keras))) install.packages("keras")
if(!(require(dplyr))) install.packages("dplyr")
if(!(require(e1071))) install.packages("e1071")
if(!(require(kernlab))) install.packages("kernlab")
if(!(require(caret))) install.packages("caret")
if(!(require(ggplot2))) install.packages("ggplot2")
if(!(require(C50))) install.packages("C50")
if(!(require(bibtex))) install.packages("bibtex")
```


```{r ficheros, include=FALSE}
# Fichero human_data.txt con los datos de las secuencias con la clase de proteínas 
# Lo hacemos parametrizado
data <- params$data
```

-----------------------------------------------------------

# 1. Introducción

Se dispone del resultado de 1200 electrocardiogramas (ECG) en pacientes con 
algún de estos 4 tipos de problemas cardíacos: Arrhythmia (ARR), Congestive 
Heart Failure (CHF), Atrial Fibrillation (AFF), Normal Sinus Rhythm (NSR). 
El número de variables recogidas es de 54. La primera variable RECORD se usa 
como identificador. La ultima variable corresponde a la clase y el resto son las
variables explicativas de tipo numérico. Como muestra se presentan las 8 
primeras:  

• hbpermin: Heart beat per minute
• Pseg: P wave segment length in ms
• PQseg: PQ segment length in ms
• QRSseg: QRS segment length in ms
• QRseg: QR segment length in ms
• QTseg: QT segment length in ms
• RSseg: RS segment length in ms
• STseg: ST segment length in ms
  
# 2. Objetivo
  
El objetivo de este análisis es **predecir el tipo de dolencia cardíaca** de los 
pacientes a partir de la información recogida en el ECG. Los datos se encuentran
en el fichero ECGCvdata.csv. La columna 56 contiene la clase.  

En esta PEC se analizan los datos mediante la **implementación** de los 
diferentes **algoritmos estudiados:**  
*k-Nearest Neighbour, Naive Bayes, Artificial Neural Network, Support Vector 
Machine, Arbol de Decisión y Random Forest* para **predecir** el tipo de 
docencia cardíaca.


# 3 Datos

## Lectura de datos

Leemos los datos del fichero *ECGCvdata.csv*. 

```{r chunck_3_1, echo = FALSE}
# Cargamos el archivo ECGCvdata.csv en un DataFrame
ecgcv_rawdata_df <- read.csv(data)

# Obtenemos el número de filas y columnas
dimensiones <- dim(ecgcv_rawdata_df)
filas <- dimensiones[1]
columnas <- dimensiones[2]
```

Nuestro fichero tiene `r filas` filas y `r columnas` columnas.

## Exploración de datos

Vemos si hay valores ausentes. 

```{r chunck_3_2, echo = FALSE}
# Cargamos el paquete dplyr Lo utilizaremos para operar con los df
require(dplyr)

# Extraemos las dos primeras columnas de nuestro df y las guardamos.
id_class_columnas <- ecgcv_rawdata_df %>% select (RECORD, ECG_signal)
# Data Frame sin las columnas "RECORD" y "ECG_signal" (class)
ecgcv_rawdata_sin_class_df <- ecgcv_rawdata_df %>% select (-RECORD, -ECG_signal)
```

Eliminamos las variables con datos ausentes ("missing")

```{r chunck_3_3, echo = FALSE}
# Verificamos que no haya valores anómalos (nulos) en el DataFrame

# Identificamos las columnas que contienen al menos un NaN
columnas_con_nan <- apply(ecgcv_rawdata_sin_class_df, 2, function(x) any(is.nan(x)))
# Excluimos las columnas con NaN del dataframe
ecgcv_data_df <- ecgcv_rawdata_sin_class_df[, !columnas_con_nan]
# Añadimos la columna "ECG_signal" (es la "class")
ecgcv_data_df <- cbind(id_class_columnas[,2], ecgcv_data_df)
# Añadimos nombres a la primera columna "class" (ECG_signal)
names(ecgcv_data_df)[1] <- c("class")
# Convertimos la columna 'class' en factor
ecgcv_data_df$class <- factor(ecgcv_data_df$class)
```

## Separación de datos Training/Test
  
Utilizamos la semilla aleatoria 12345 para separar los datos en dos partes, una 
parte para training (67%) y una parte para test (33%).
  
  
```{r chunck_3_b_1}
# Separamos la base de datos en dos grupos: el grupo data.train con el 67 % de 
# las observaciones (params$p.train) y el grupo data.test con el resto

# Fijamos la semilla para que los cálculos pseudo-aleatorios sean reproducibles
set.seed(params$seed)

# Obtenemos el número total de filas (datos) de parkinson
n <- nrow(ecgcv_data_df)
# Calculamos el número de filas para entrenamiento y pruebas
n_train <- round(params$p.train * n) # 67%
n_test <- n - n_train # 33%
# Obtenemos los índices de filas al azar para entrenamiento
indices_train <- sample(1:n, n_train)
# Seleccionamos las filas para entrenamiento
data.train <- ecgcv_data_df[indices_train,]
# Seleccionamos las filas restantes para pruebas
data.test <- ecgcv_data_df[-indices_train, ]

require(dplyr)
# Seleccionamos los datos de "train" sin la clase
data.train_sin <- data.train %>% select(-class)
# Creamos los labels de class de "train" para el algoritmo knn
train_labels <- data.train[, 1]
# Seleccionamos los datos de "test" sin la clase
data.test_sin <- data.test %>% select(-class)
# Creamos los labels de class de "test" para el algoritmo knn
test_labels <- data.test[, 1]
```

# 4 Moldelos ML de clasificación

## a) k-Nearest Neighbour kNN {.tabset .tabset-fade .tabset-pills}

### k = 1

```{r chunck_4_a_1}

# Utilizamos la función knn del paquete "class"
require("class")

# Modelo knn utilizando una k = 1
mod_knn_1 <- knn(train = data.train_sin, test = data.test_sin, 
                  cl = train_labels, k = 1, prob = TRUE)

# Creamos un data frame con los resultados predichos y actuales
resultados_knn_1 <- data.frame(predichos = mod_knn_1, actuales = test_labels)

# Evaluamos el modelo
library(caret)
# Utilizamos la función confusionMatrix del paquete caret
conf.mat.knn_1 <- confusionMatrix(resultados_knn_1$predichos, resultados_knn_1$actuales)
conf.mat.knn_1

# Obtenemos la precisión (accuracy)
accuracy_knn_1 <- conf.mat.knn_1$overall["Accuracy"]
# Obtenemos el valor del coeficiente kappa
kappa_knn_1 <- conf.mat.knn_1$overall["Kappa"]
```

### k = 3

```{r chunck_4_a_2}

# Modelo knn utilizando una k = 3
mod_knn_3 <- knn(train = data.train_sin, test = data.test_sin, 
                  cl = train_labels, k = 3, prob = TRUE)
# Creamos un data frame con los resultados predichos y actuales
resultados_knn_3 <- data.frame(predichos = mod_knn_3, actuales = test_labels)
# Utilizamos la función confusionMatrix del paquete caret
conf.mat.knn_3 <- confusionMatrix(resultados_knn_3$predichos, resultados_knn_3$actuales)
conf.mat.knn_3
# Obtenemos la precisión (accuracy)
accuracy_knn_3 <- conf.mat.knn_3$overall["Accuracy"]
# Obtenemos el valor del coeficiente kappa
kappa_knn_3 <- conf.mat.knn_3$overall["Kappa"]
```

### k = 5

```{r chunck_4_a_3}

# Modelo knn utilizando una k = 5
mod_knn_5 <- knn(train = data.train_sin, test = data.test_sin, 
                  cl = train_labels, k = 5, prob = TRUE)
# Creamos un data frame con los resultados predichos y actuales
resultados_knn_5 <- data.frame(predichos = mod_knn_5, actuales = test_labels)
# Utilizamos la función confusionMatrix del paquete caret
conf.mat.knn_5 <- confusionMatrix(resultados_knn_5$predichos, resultados_knn_5$actuales)
conf.mat.knn_5
# Obtenemos la precisión (accuracy)
accuracy_knn_5 <- conf.mat.knn_5$overall["Accuracy"]
# Obtenemos el valor del coeficiente kappa
kappa_knn_5 <- conf.mat.knn_5$overall["Kappa"]
```

### k = 7

```{r chunck_4_a_4}

# Modelo knn utilizando una k = 7
mod_knn_7 <- knn(train = data.train_sin, test = data.test_sin, 
                  cl = train_labels, k = 7, prob = TRUE)
# Creamos un data frame con los resultados predichos y actuales
resultados_knn_7 <- data.frame(predichos = mod_knn_7, actuales = test_labels)
# Utilizamos la función confusionMatrix del paquete caret
conf.mat.knn_7 <- confusionMatrix(resultados_knn_7$predichos, resultados_knn_7$actuales)
conf.mat.knn_7
# Obtenemos la precisión (accuracy)
accuracy_knn_7 <- conf.mat.knn_7$overall["Accuracy"]
# Obtenemos el valor del coeficiente kappa
kappa_knn_7 <- conf.mat.knn_7$overall["Kappa"]
```

### Resultados knn

Modelo|Accuraccy|kappa
:----|:----|:----:
k=1|`r accuracy_knn_1`|`r kappa_knn_1`
k=3|`r accuracy_knn_3`|`r kappa_knn_3`
k=5|`r accuracy_knn_5`|`r kappa_knn_5`
k=7|`r accuracy_knn_7`|`r kappa_knn_7`
  
Si nos fijamos en la información que nos da la función ConfusionMatrix() vemos 
que la k que da mejores resultados es la k=1. En este caso la «accuracy», que es
la probabilidad de que el modelo prediga correctamente un verdadero positivo o 
un verdadero negativo, es de `r accuracy_knn_1` mientras que en las otras k es de 
`r accuracy_knn_3`, `r accuracy_knn_5` y `r accuracy_knn_7`.
Si nos fijamos en el estadístico *Kappa*, que ajusta la «accuracy» teniendo en 
cuenta una correcta predicción por azar, vemos que también con k = 1 obtenemos 
el mejor resultado, `r round(kappa_knn_1, digits = 3)` que se considera 
«Good agreement» aunque que con las otras tres k’s también obtenemos un 
«Good agreement».


## b) Naive Bayes {.tabset .tabset-fade .tabset-pills}

### laplace = 0

```{r chunck_4_b_1}

require(e1071)
mod_naive.bayes <- naiveBayes(data.train_sin, train_labels, laplace=0)
#probabilidades condicionadas
#mod_naive.bayes$tables[1:4]

# Predicción del modelo Naive Bayes
pred_naive.bayes <- predict(mod_naive.bayes, data.test_sin)

# Métricas de rendimiento
#require(caret)
# Matriz de confusión
res <- table(pred_naive.bayes, test_labels)
conf.mat.naive.bayes <- confusionMatrix(res)
# Visualizamos
conf.mat.naive.bayes
```
  
### laplace = 1

```{r chunck_4_b_2}

require(e1071)
mod_naive.bayes_l1 <- naiveBayes(data.train_sin, train_labels, laplace=1)
#probabilidades condicionadas
#mod_naive.bayes$tables[1:4]

# Predicción del modelo Naive Bayes
pred_naive.bayes_l1 <- predict(mod_naive.bayes_l1, data.test_sin)

# Métricas de rendimiento
#require(caret)
# Matriz de confusión
res <- table(pred_naive.bayes_l1, test_labels)
conf.mat.naive.bayes_l1 <- confusionMatrix(res)
# Visualizamos
conf.mat.naive.bayes_l1
```
### Resultados Naive Bayes

Modelo|Accuraccy|kappa
:----|:----|:----:
NaiveBayes l = 0|`r conf.mat.naive.bayes$overall["Accuracy"]`|`r conf.mat.naive.bayes$overall["Kappa"]`
NaiveBayes l = 1|`r conf.mat.naive.bayes_l1$overall["Accuracy"]`|`r conf.mat.naive.bayes_l1$overall["Kappa"]`

Los resultados con ambas condiciones, `laplace = 0` y `laplace = 1`, son 
idénticos. Nos quedamos con el modelo más simple así que no tiene sentido 
aplicar `laplace = 1` para mejorar el modelo.

## c) ANN {.tabset .tabset-fade .tabset-pills}

### 15 nodos en una capa oculta

```{r chunck_4_c_1, eval = FALSE}
require(keras)

# Definimos el modelo
modelo1 <- keras_model_sequential() 
# Añadimos una capa oculta densa de 15 nodos con activación relu
modelo1 %>% 
  layer_dense(units = 15, input_shape = c(dim(data.train_sin)[2]), activation = 'relu') %>%
  # Añadimos un Dropout del 20%
  #layer_dropout(rate = 0.2) %>%
  # Generamos la capa de salida con activación softmax (4 nodos para las 4 clases)
  layer_dense(units = 4, activation = 'softmax')

# Mostramos el resumen del modelo
summary(modelo1)

```

```{r chunck_4_c_2, eval = FALSE}
modelo1 %>% compile(
  loss = 'sparse_categorical_crossentropy',
  optimizer = 'adam',
  metrics = c('accuracy')
)
```

```{r chunck_4_c_3, eval = FALSE}
early_stopping <- callback_early_stopping(
  monitor = 'val_loss',
  patience = 10,
  restore_best_weights = TRUE)
```

```{r chunck_4_c_4, eval = FALSE}
x_train <- data.train_sin
y_train <- as.data.frame(as.character(train_labels))

historia_modelo1 <- modelo1 %>% fit(
  x_train, y_train,
  epochs = 5,
  batch_size = 32,
  validation_split = 0.2)
```

## d) Modelos SVM {.tabset .tabset-fade .tabset-pills}
  
Utilizamos el kernel lineal y el kernel RBF para crear sendos modelos SVM 
basados en el training para predecir las clases en los datos del test.

### kernel lineal

Relalizamos el modelo predictivo con el kernel lineal.
  
```{r chunck_4_d_1}
require(kernlab)
# Hacemos el clasificador con el modelo lineal ksvm. 
mod_ksvm_lineal <- ksvm(class ~ ., data = data.train, kernel = "vanilladot")
# Vemos la información del modelo
mod_ksvm_lineal
```

Hacemos la predicción de los datos del test con el kernel lineal  

```{r chunck_4_d_2}
# Predicción del test con el kernel lineal
pred_ksvm_lineal <- predict(mod_ksvm_lineal, data.test)

# Métricas de rendimiento
require(caret)
# Matriz de confusión
res <- table(pred_ksvm_lineal, data.test$class)
conf.mat.ksvm.lineal <- confusionMatrix(res, positive="+")
# Visualizamos
conf.mat.ksvm.lineal
```

### kernel RBF

Relalizamos el modelo predictivo con el kernel RBF

```{r chunck_3_c_3}

#require(kernlab)
# Hacemos el clasificador con el modelo ksvm RBF.
mod_ksvm_RBF <- ksvm(class ~ ., data = data.train, kernel = "rbfdot")
# Vemos la información del modelo
mod_ksvm_RBF
```

Hacemos la predicción de los datos del test con el kernel RBF  

```{r chunck_3_c_4}
# Predicción del test con el kernel RBF
pred_ksvm_RBF <- predict(mod_ksvm_RBF, data.test)

# Métricas de rendimiento
# require(caret)
# Matriz de confusión
res <- table(pred_ksvm_RBF, data.test$class)
conf.mat.ksvm.RBF <- confusionMatrix(res, positive="+")
# Visualizamos
conf.mat.ksvm.RBF
```

### Resultados SVM

Modelo|Accuraccy|kappa
:----|:----|:----:
ksvm.lineal|`r conf.mat.ksvm.lineal$overall["Accuracy"]`|`r conf.mat.ksvm.lineal$overall["Kappa"]`
ksvm.RBF|`r conf.mat.ksvm.RBF$overall["Accuracy"]`|`r conf.mat.ksvm.RBF$overall["Kappa"]`
  
Los modelos SVM entrenados con los datos que hemos separado para `ksvm` nos dan 
ligeramente distintos resultados. En igualdad de condiciones lo apropiado sería
escoger el modelo más simple. En todo caso, escogemos ksvm lineal que nos da 
mejores resultados y además es el modelo más simple.

## e) Árbol de Clasificación {.tabset .tabset-fade .tabset-pills}

### boosting activado

```{r chunck_4_e_1}
require(C50)
# Hacemos el clasificador con el modelo lineal ksvm. 
mod_arbol <- C5.0(data.train, train_labels, trials = 1, cost = NULL)
# Vemos la información del modelo
mod_arbol
# Vemos las tree's decistions
summary(mod_arbol)
```
Hacemos la predicción de los datos del test con el kernel RBF  

```{r chunck_4_e_2}
# Predicción del tree model
pred_mod_arbol <- predict(mod_arbol, data.test)

# Métricas de rendimiento
# require(caret)
# Matriz de confusión
res <- table(pred_mod_arbol, test_labels)
conf.mat.mod_arbol <- confusionMatrix(res)
# Visualizamos
conf.mat.mod_arbol
```

### boosting inactivado


# Referencias  

